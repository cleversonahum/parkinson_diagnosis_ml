{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import entropy\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import f_classif, SelectKBest, mutual_info_classif\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_absolute_error, roc_curve, auc, roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (195, 24)\n",
      "name                 object\n",
      "MDVP:Fo(Hz)         float64\n",
      "MDVP:Fhi(Hz)        float64\n",
      "MDVP:Flo(Hz)        float64\n",
      "MDVP:Jitter(%)      float64\n",
      "MDVP:Jitter(Abs)    float64\n",
      "MDVP:RAP            float64\n",
      "MDVP:PPQ            float64\n",
      "Jitter:DDP          float64\n",
      "MDVP:Shimmer        float64\n",
      "MDVP:Shimmer(dB)    float64\n",
      "Shimmer:APQ3        float64\n",
      "Shimmer:APQ5        float64\n",
      "MDVP:APQ            float64\n",
      "Shimmer:DDA         float64\n",
      "NHR                 float64\n",
      "HNR                 float64\n",
      "status                int64\n",
      "RPDE                float64\n",
      "DFA                 float64\n",
      "spread1             float64\n",
      "spread2             float64\n",
      "D2                  float64\n",
      "PPE                 float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "data_csv = \"parkinsons.data\"\n",
    "df = pd.read_csv(data_csv)#, names=['ID','Clump','U_Cell_size','U_Cell_shape','Marginal_Adhesion','SE_epitelial_cell_size','Bare_nuclei','bland_chromatin','Normal_Nucleoli','Mitoses','Class'])\n",
    "print('Dataset shape: ', df.shape)\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Dataset shape:  (195, 23)\n"
     ]
    }
   ],
   "source": [
    "# Verifying null values and deleting name from dataset\n",
    "null_columns=df.columns[df.isnull().any()]\n",
    "print(df[df.isnull().any(axis=1)][null_columns].head())\n",
    "# Drop the lines with null values\n",
    "df = df.dropna()\n",
    "# Removing name column since it won't be considered to the training\n",
    "df.pop('name')\n",
    "print('Dataset shape: ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDVP:Fo(Hz) \n",
      "Min Value:   88.333 \n",
      "Max Value:  260.105 \n",
      "\n",
      "\n",
      "MDVP:Fhi(Hz) \n",
      "Min Value:   102.145 \n",
      "Max Value:  592.03 \n",
      "\n",
      "\n",
      "MDVP:Flo(Hz) \n",
      "Min Value:   65.476 \n",
      "Max Value:  239.17 \n",
      "\n",
      "\n",
      "MDVP:Jitter(%) \n",
      "Min Value:   0.00168 \n",
      "Max Value:  0.03316 \n",
      "\n",
      "\n",
      "MDVP:Jitter(Abs) \n",
      "Min Value:   7.000000000000001e-06 \n",
      "Max Value:  0.00026000000000000003 \n",
      "\n",
      "\n",
      "MDVP:RAP \n",
      "Min Value:   0.0006799999999999999 \n",
      "Max Value:  0.02144 \n",
      "\n",
      "\n",
      "MDVP:PPQ \n",
      "Min Value:   0.0009199999999999999 \n",
      "Max Value:  0.01958 \n",
      "\n",
      "\n",
      "Jitter:DDP \n",
      "Min Value:   0.0020399999999999997 \n",
      "Max Value:  0.06433 \n",
      "\n",
      "\n",
      "MDVP:Shimmer \n",
      "Min Value:   0.00954 \n",
      "Max Value:  0.11907999999999999 \n",
      "\n",
      "\n",
      "MDVP:Shimmer(dB) \n",
      "Min Value:   0.085 \n",
      "Max Value:  1.302 \n",
      "\n",
      "\n",
      "Shimmer:APQ3 \n",
      "Min Value:   0.00455 \n",
      "Max Value:  0.056470000000000006 \n",
      "\n",
      "\n",
      "Shimmer:APQ5 \n",
      "Min Value:   0.0057 \n",
      "Max Value:  0.0794 \n",
      "\n",
      "\n",
      "MDVP:APQ \n",
      "Min Value:   0.00719 \n",
      "Max Value:  0.13777999999999999 \n",
      "\n",
      "\n",
      "Shimmer:DDA \n",
      "Min Value:   0.013640000000000001 \n",
      "Max Value:  0.16942000000000002 \n",
      "\n",
      "\n",
      "NHR \n",
      "Min Value:   0.00065 \n",
      "Max Value:  0.31482 \n",
      "\n",
      "\n",
      "HNR \n",
      "Min Value:   8.441 \n",
      "Max Value:  33.047 \n",
      "\n",
      "\n",
      "status \n",
      "Min Value:   0 \n",
      "Max Value:  1 \n",
      "\n",
      "\n",
      "RPDE \n",
      "Min Value:   0.25656999999999996 \n",
      "Max Value:  0.6851510000000001 \n",
      "\n",
      "\n",
      "DFA \n",
      "Min Value:   0.574282 \n",
      "Max Value:  0.8252879999999999 \n",
      "\n",
      "\n",
      "spread1 \n",
      "Min Value:   -7.964983999999999 \n",
      "Max Value:  -2.434031 \n",
      "\n",
      "\n",
      "spread2 \n",
      "Min Value:   0.006274 \n",
      "Max Value:  0.45049300000000003 \n",
      "\n",
      "\n",
      "D2 \n",
      "Min Value:   1.4232870000000002 \n",
      "Max Value:  3.671155 \n",
      "\n",
      "\n",
      "PPE \n",
      "Min Value:   0.044538999999999995 \n",
      "Max Value:  0.527367 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset distribution values\n",
    "for name, values in df.iteritems():\n",
    "    print (name, '\\nMin Value:  ', np.min(values), '\\nMax Value: ', np.max(values), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total     = 195 -> 100%\n",
      "Healthy    = 48 -> 24.615384615384617%\n",
      "Parkinson = 147 -> 75.38461538461539%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total     = {len(df)} -> 100%\")\n",
    "print(f\"Healthy    = {len(df[df.status == 0])} -> {len(df[df.status == 0])/len(df) *100}%\")\n",
    "print(f\"Parkinson = {len(df[df.status == 1])} -> {len(df[df.status == 1])/len(df) *100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195, 22)\n",
      "(195,)\n"
     ]
    }
   ],
   "source": [
    "# Separate entries from outputs\n",
    "dataset = df.to_numpy() # Converting from Pandas dataframe to Numpy\n",
    "entries = df.loc[:, df.columns != 'status'].to_numpy(dtype=np.float64)\n",
    "outputs = df['status'].to_numpy(dtype=np.int64)\n",
    "print(entries.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape:\n",
      "Entries:  (156, 22) \n",
      "Output:  (156,) \n",
      "\n",
      "\n",
      "Test dataset shape:\n",
      "Entries:  (39, 22) \n",
      "Output:  (39,)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset between train and test\n",
    "seed = 10 # Set seed to get invariant results\n",
    "test_size = 0.2\n",
    "x_train, x_test, y_train, y_test = train_test_split(entries, outputs, test_size=test_size, random_state=seed)\n",
    "print('Train dataset shape:\\nEntries: ', x_train.shape, '\\nOutput: ', y_train.shape, '\\n\\n')\n",
    "print('Test dataset shape:\\nEntries: ', x_test.shape, '\\nOutput: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10-fold validation set for training\n",
    "K = 10\n",
    "kf = StratifiedShuffleSplit(n_splits=K, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree classifier\n",
    "dt = tree.DecisionTreeClassifier(random_state=seed, criterion=\"entropy\", min_samples_leaf=2, min_samples_split=5, max_depth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=seed, min_samples_split=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "# Building the NN\n",
    "class Neural_binary_classifier:\n",
    "    def __init__(self, input_dim ,normalize_factor=0):\n",
    "        self.normalize_factor = normalize_factor if normalize_factor > 0 else 1\n",
    "        lr = 0.001          # learning rate\n",
    "        lr_decay = 0.0005   # learning rate decay\n",
    "        n_mini_batch = 100  # mini-batch length\n",
    "        activation_fcn = \"relu\"\n",
    "        optimizer = Adam(lr=lr, decay=lr_decay)\n",
    "        h_n = 100\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(h_n, input_dim=input_dim, activation=activation_fcn,\n",
    "                    kernel_regularizer=tf.keras.regularizers.l1(0.0001)))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    def fit(self,x_train,y_train):\n",
    "        self.model.fit(x_train/self.normalize_factor, y_train,\n",
    "                        epochs=200,\n",
    "                        batch_size=50,\n",
    "                        verbose=0,\n",
    "                        callbacks=[\n",
    "                            EarlyStopping(\n",
    "                                monitor=\"loss\", mode=\"min\", min_delta=0.001, patience=30, verbose=1\n",
    "                            )\n",
    "                        ],\n",
    "                      )\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        y_valid_pred = self.model.predict(x_test/self.normalize_factor)\n",
    "        to_bin = np.vectorize(lambda x : 1 if x > 0.5 else 0)\n",
    "        \n",
    "        return to_bin(y_valid_pred.flatten())\n",
    "\n",
    "ann = Neural_binary_classifier(entries.shape[1], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes classifier\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM classifier\n",
    "svm = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [(dt, \"Decision tree\"), (gnb, \"Naive Bayes\"), (ann, \"Neural network\"), (rf, \"Random forest\"), (svm, \"SVM\"), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Classifier type:  Decision tree , Validation Accuracy =  0.5625\n",
      "Classifier type:  Naive Bayes , Validation Accuracy =  0.75\n",
      "Classifier type:  Neural network , Validation Accuracy =  0.75\n",
      "Classifier type:  Random forest , Validation Accuracy =  0.6875\n",
      "Classifier type:  SVM , Validation Accuracy =  0.75\n",
      "\n",
      "\n",
      "Fold  2\n",
      "Classifier type:  Decision tree , Validation Accuracy =  0.6875\n",
      "Classifier type:  Naive Bayes , Validation Accuracy =  0.75\n",
      "Classifier type:  Neural network , Validation Accuracy =  0.6875\n",
      "Classifier type:  Random forest , Validation Accuracy =  0.75\n",
      "Classifier type:  SVM , Validation Accuracy =  0.75\n",
      "\n",
      "\n",
      "Fold  3\n",
      "Classifier type:  Decision tree , Validation Accuracy =  0.8125\n",
      "Classifier type:  Naive Bayes , Validation Accuracy =  0.8125\n",
      "Classifier type:  Neural network , Validation Accuracy =  0.8125\n",
      "Classifier type:  Random forest , Validation Accuracy =  0.9375\n",
      "Classifier type:  SVM , Validation Accuracy =  0.8125\n",
      "\n",
      "\n",
      "Fold  4\n",
      "Classifier type:  Decision tree , Validation Accuracy =  0.8125\n",
      "Classifier type:  Naive Bayes , Validation Accuracy =  0.5625\n"
     ]
    }
   ],
   "source": [
    "# Training classifiers using cross-validation\n",
    "fold_number = 1\n",
    "for train_indexes, valid_indexes in kf.split(x_train, y_train):\n",
    "    print(\"Fold \", fold_number)\n",
    "    for classifier, label in classifiers:\n",
    "        classifier.fit(x_train[train_indexes], y_train[train_indexes])\n",
    "        y_valid_pred = classifier.predict(x_train[valid_indexes])\n",
    "        print(\"Classifier type: \",label, \", Validation Accuracy = \", accuracy_score(y_train[valid_indexes], y_valid_pred))\n",
    "    print('\\n')\n",
    "    fold_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing classifiers\n",
    "for classifier, label in classifiers:\n",
    "    y_test_estimative = classifier.predict(x_test)\n",
    "    print(\"Classifier type: \", label, \", Test Accuracy = \", accuracy_score(y_test, y_test_estimative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrixes = np.zeros((len(classifiers), 4))\n",
    "for index, classifier_info in enumerate(classifiers):\n",
    "    confusion_matrixes[index,:] = np.array([confusion_matrix(y_test, classifier_info[0].predict(x_test)).ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(dataframe, metric_indexes, indexes_results, orientation, xlabel, ylabel):\n",
    "    classifier_labels = [\"Decision tree\", \"Naive Bayes\", \"Neural network\", \"Random forest\", \"SVM\"]\n",
    "    df_perf_results = pd.DataFrame(dataframe, columns=metric_indexes)\n",
    "    df_perf_results.insert(0, 'classifier_type', classifier_labels, True)\n",
    "    df_perf_results = pd.melt(df_perf_results, id_vars=['classifier_type'], value_vars=indexes_results, var_name='Metric')\n",
    "    \n",
    "    # Plot confusion matrixes for each classifier\n",
    "    plt.figure()\n",
    "    if orientation==\"h\":\n",
    "        x = \"value\"\n",
    "        y = \"classifier_type\"\n",
    "        gridon = \"x\"\n",
    "    else:\n",
    "        y = \"value\"\n",
    "        x = \"classifier_type\"\n",
    "        gridon = \"y\"\n",
    "\n",
    "    x = \"value\" if orientation==\"h\" else \"classifier_type\"\n",
    "    y = \"classifier_type\" if orientation==\"h\" else \"value\"\n",
    "    sns.catplot(data=df_perf_results, kind=\"bar\", orient=orientation, x=x, y=y, hue=\"Metric\", ci=\"sd\", palette=\"dark\", alpha=.6, height=6)\n",
    "    plt.ylabel(xlabel, fontsize=14)\n",
    "    plt.xlabel(ylabel, fontsize=14)\n",
    "    if indexes_results == [\"AUC\", \"CA\", \"Pre\", \"Rec\"]:\n",
    "        plt.ylim([0.88, 1])\n",
    "    plt.grid(axis=gridon)\n",
    "    plt.show()\n",
    "\n",
    "# Generate dataset to plot using seaborn package\n",
    "indexes = [\"TN\", \"FP\", \"FN\", \"TP\"]\n",
    "indexes_result1 = [\"TP\", \"FP\", \"FN\", \"TN\"]\n",
    "\n",
    "plot_metrics(confusion_matrixes, indexes, indexes_result1, \"v\", \"Classifiers\", \"No. of samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion_matrixes = pd.DataFrame(confusion_matrixes, columns=indexes, index=[label for _, label in classifiers])\n",
    "df_confusion_matrixes.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_metrics(confusion_values):\n",
    "    # [0] = TN, [1] = FP, [2] = FN, [3] = TP\n",
    "    # 4.1 accuracy\n",
    "    accuracy = (confusion_values[3] + confusion_values[0]) / (np.sum(confusion_values))\n",
    "    # 4.2 precision\n",
    "    precision = confusion_values[3] / (confusion_values[3] + confusion_values[1])\n",
    "    # 4.3 specificity\n",
    "    specificity = confusion_values[0] / (confusion_values[0] + confusion_values[1])\n",
    "    # 4.4 TP rate\n",
    "    tp_rate = confusion_values[3] / (confusion_values[3] + confusion_values[2])\n",
    "    # 4.5 FP rate\n",
    "    fp_rate = confusion_values[1] / (confusion_values[1] + confusion_values[0])\n",
    "    # 4.6 NPV\n",
    "    npv = confusion_values[0] / (confusion_values[0] + confusion_values[2])\n",
    "    # 4.7 Rate of Misclassification\n",
    "    misclassification_rate = (confusion_values[1] + confusion_values[2]) / (np.sum(confusion_values))\n",
    "    # 4.8 F1 Score\n",
    "    f1_score = 2*(precision * tp_rate) / (precision + tp_rate)\n",
    "\n",
    "    return np.array([accuracy, precision, specificity, tp_rate, fp_rate, npv, misclassification_rate, f1_score])\n",
    "\n",
    "perf_results = np.zeros((confusion_matrixes.shape[0], 10))\n",
    "for i in np.arange(confusion_matrixes.shape[0]):\n",
    "    perf_results[i,0:8] = perf_metrics(confusion_matrixes[i,:])\n",
    "\n",
    "# Calculate AUC and ROC curve and Mean Absolute Error (MEA)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "mae = dict()\n",
    "\n",
    "for index, classifier_info in enumerate(classifiers):\n",
    "    fpr[classifier_info[1]], tpr[classifier_info[1]], _ = roc_curve(y_test, classifier_info[0].predict(x_test))\n",
    "    roc_auc[classifier_info[1]] = auc(fpr[classifier_info[1]], tpr[classifier_info[1]])\n",
    "    mae[classifier_info[1]] = mean_absolute_error(y_test, classifier_info[0].predict(x_test))\n",
    "perf_results[:,8] = [roc_auc[i] for i in roc_auc]\n",
    "perf_results[:,9] = [mae[i] for i in mae]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_indexes = [\"CA\", \"Pre\", \"Spec\", \"Rec\", \"FPR\", \"NPV\", \"RMC\", \"F1\", \"AUC\", \"MAE\"] # that stands for Classification accuracy, Precision, Specificity, Recall/TP rate, \n",
    "# False positive rate, negative predictive value, misclassification rate and F1, respectively.\n",
    "indexes_result2 = [\"Pre\", \"Rec\", \"AUC\", \"MAE\", \"CA\"]\n",
    "\n",
    "plot_metrics(perf_results, metric_indexes, indexes_result2, \"h\", \"No. of samples\", \"Classifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_results = pd.DataFrame(perf_results, columns=metric_indexes, index=[label for _, label in classifiers])\n",
    "df_perf_results[indexes_result2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 4 equivalent\n",
    "result_labels = [\"TP\", \"FP\", \"Pre\", \"Rec\", \"AUC\", \"MAE\", \"CA\"]\n",
    "df_results_original = pd.concat([df_confusion_matrixes.T, df_perf_results.T]).T\n",
    "df_results_original[result_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we start to evaluate results using a modified dataset processed by MFEA technique described in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df = pd.read_csv(data_csv)\n",
    "mod_df.pop('name')\n",
    "# Separate entries from outputs\n",
    "mod_dataset = mod_df.to_numpy() # Converting from Pandas dataframe to Numpy\n",
    "mod_entries = mod_df.loc[:, mod_df.columns != 'status'].to_numpy(dtype=np.float64)\n",
    "mod_outputs = mod_df['status'].to_numpy(dtype=np.int64)\n",
    "print(mod_entries.shape)\n",
    "print(mod_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr(x):\n",
    "    array = pd.plotting.autocorrelation_plot(x).lines[5].get_data()[1]\n",
    "    plt.close()\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First filter the collums that have any value of corcoef greater than 0.95\n",
    "corr = np.corrcoef(mod_dataset.T)\n",
    "corr[np.where(corr == 1)] = 0\n",
    "valid_idx = np.array([any(i > 0.95) for i in corr])\n",
    "# valid_idx = np.where(valid_idx == False)[0]\n",
    "valid_idx = np.arange(len(valid_idx))\n",
    "\n",
    "# With the filtered dataset, find out the pitch values\n",
    "fa_db = mod_dataset[:,valid_idx]\n",
    "\n",
    "# The pitch value consist in the period between 2 peaks of autocorrelation\n",
    "fa_db_autocorr = []\n",
    "for i in range(fa_db.T.shape[0]):\n",
    "    fa_db_autocorr.append(autocorr(fa_db.T[i]))\n",
    "\n",
    "# Eliminate the transient in the autocorrelation\n",
    "fa_db_autocorr = np.array(fa_db_autocorr)\n",
    "fa_db_autocorr[:,range(0,15)] = 0\n",
    "\n",
    "# Get the max value indexes\n",
    "pitch_values = np.array([np.where(row == max(row))[0][0] for row in fa_db_autocorr])\n",
    "\n",
    "# pitch_values = [1/i for i in pitch_values]\n",
    "fa_order = np.array([valid_idx,pitch_values]).T\n",
    "fa_order = fa_order[np.argsort(pitch_values)][:,0]\n",
    "fa_order = fa_order[::-1]\n",
    "fa_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SelectKBest(score_func=f_classif, k=\"all\")\n",
    "sa_fit = sa.fit(mod_entries, mod_outputs)\n",
    "sa_scores = sa_fit.scores_\n",
    "sa_order = np.argsort(sa_scores.argsort())+1\n",
    "sa_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_info_gain = mutual_info_classif(mod_entries, mod_outputs)\n",
    "ta_entropy = [entropy(feature) for feature in mod_entries.T]\n",
    "ta_scores = ta_info_gain/ta_entropy\n",
    "ta_order = np.argsort(ta_scores.argsort())+1\n",
    "ta_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo_scores = mutual_info_classif(mod_entries, mod_outputs)\n",
    "fo_order = np.argsort(ta_scores.argsort())+1\n",
    "fo_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fifth Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "def feature_plot(classifier, feature_names, top_features=11):\n",
    " coef = classifier.coef_.ravel()\n",
    " top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    " top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    " top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    " plt.figure(figsize=(18, 7))\n",
    " colors = ['green' if c < 0 else 'blue' for c in coef[top_coefficients]]\n",
    " plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    " feature_names = np.array(feature_names)\n",
    " plt.xticks(np.arange(1 + 2 * top_features), feature_names[top_coefficients], rotation=45, ha='right')\n",
    " plt.show()\n",
    " return  top_coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedsvm = svm.LinearSVC().fit(x_train, y_train)\n",
    "ffa_order = feature_plot(trainedsvm, np.arange(23))[::-1]\n",
    "ffa_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting features based on agent scores/order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = np.array([[fa_order[:22]], [sa_order], [ta_order], [fo_order], [ffa_order]])\n",
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First filter, selecting 14 features by frequency\n",
    "frequency = np.squeeze(np.sum(orders<15, axis=0))\n",
    "print(\"Frequency: \", frequency)\n",
    "order = np.argsort(np.argsort(-frequency))+1\n",
    "print(\"Order: \", order)\n",
    "frequency_order = np.where(order>14, 0, order)\n",
    "print(\"First 14 selected features: \", frequency_order) # Only first 14th features were selected in this first step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second filter to select 11 features from 14\n",
    "first_filter_mask = frequency_order!=0\n",
    "orders_sum = np.squeeze(np.sum(orders, axis=0))\n",
    "rank = np.nan_to_num((orders_sum/frequency) * first_filter_mask)\n",
    "rank = np.argsort(np.argsort(np.where(rank==0, 99, rank))) +1\n",
    "features_mask = rank<12\n",
    "selected_features_labels = mod_df.columns[mod_df.columns != \"status\"][features_mask]\n",
    "print(\"Selected features: \", selected_features_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new entries based on feature selection, now only 11 features are used\n",
    "selected_entries = mod_entries[:, features_mask]\n",
    "print(\"New entries shape: \", selected_entries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset between train and test\n",
    "seed = 10 # Set seed to get invariant results\n",
    "test_size = 0.2\n",
    "x_train, x_test, y_train, y_test = train_test_split(selected_entries, mod_outputs, test_size=test_size, random_state=seed)\n",
    "print('Train dataset shape:\\nEntries: ', x_train.shape, '\\nOutput: ', y_train.shape, '\\n\\n')\n",
    "print('Test dataset shape:\\nEntries: ', x_test.shape, '\\nOutput: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10-fold validation set for training\n",
    "K = 10\n",
    "kf = StratifiedShuffleSplit(n_splits=K, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Decision Tree classifier\n",
    "dt = tree.DecisionTreeClassifier(random_state=seed, criterion=\"entropy\", min_samples_leaf=2, min_samples_split=5, max_depth=100)\n",
    "\n",
    "# Random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=seed, min_samples_split=5)\n",
    "\n",
    "# Building the NN\n",
    "class Neural_binary_classifier:\n",
    "    def __init__(self, input_dim ,normalize_factor=0):\n",
    "        self.normalize_factor = normalize_factor if normalize_factor > 0 else 1\n",
    "        lr = 0.001          # learning rate\n",
    "        lr_decay = 0.0005   # learning rate decay\n",
    "        n_mini_batch = 100  # mini-batch length\n",
    "        activation_fcn = \"relu\"\n",
    "        optimizer = Adam(lr=lr, decay=lr_decay)\n",
    "        h_n = 100\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(h_n, input_dim=input_dim, activation=activation_fcn,\n",
    "                    kernel_regularizer=tf.keras.regularizers.l1(0.0001)))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    def fit(self,x_train,y_train):\n",
    "        self.model.fit(x_train/self.normalize_factor, y_train,\n",
    "                        epochs=200,\n",
    "                        batch_size=50,\n",
    "                        verbose=0,\n",
    "                        callbacks=[\n",
    "                            EarlyStopping(\n",
    "                                monitor=\"loss\", mode=\"min\", min_delta=0.001, patience=30, verbose=1\n",
    "                            )\n",
    "                        ],\n",
    "                      )\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        y_valid_pred = self.model.predict(x_test/self.normalize_factor)\n",
    "        to_bin = np.vectorize(lambda x : 1 if x > 0.5 else 0)\n",
    "        \n",
    "        return to_bin(y_valid_pred.flatten())\n",
    "\n",
    "ann = Neural_binary_classifier(selected_entries.shape[1], 10)\n",
    "\n",
    "# Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# SVM classifier\n",
    "svm = svm.SVC()\n",
    "\n",
    "classifiers = [(dt, \"Decision tree\"), (gnb, \"Naive Bayes\"), (ann, \"Neural network\"), (rf, \"Random forest\"), (svm, \"SVM\"), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training classifiers using cross-validation\n",
    "fold_number = 1\n",
    "for train_indexes, valid_indexes in kf.split(x_train, y_train):\n",
    "    print(\"Fold \", fold_number)\n",
    "    for classifier, label in classifiers:\n",
    "        classifier.fit(x_train[train_indexes], y_train[train_indexes])\n",
    "        y_valid_pred = classifier.predict(x_train[valid_indexes])\n",
    "        print(\"Classifier type: \",label, \", Validation Accuracy = \", accuracy_score(y_train[valid_indexes], y_valid_pred))\n",
    "    print('\\n')\n",
    "    fold_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing classifiers\n",
    "for classifier, label in classifiers:\n",
    "    y_test_estimative = classifier.predict(x_test)\n",
    "    print(\"Classifier type: \", label, \", Test Accuracy = \", accuracy_score(y_test, y_test_estimative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrixes = np.zeros((len(classifiers), 4))\n",
    "for index, classifier_info in enumerate(classifiers):\n",
    "    confusion_matrixes[index,:] = np.array([confusion_matrix(y_test, classifier_info[0].predict(x_test)).ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset to plot using seaborn package\n",
    "indexes = [\"TN\", \"FP\", \"FN\", \"TP\"]\n",
    "indexes_result1 = [\"TP\", \"FP\", \"FN\", \"TN\"]\n",
    "\n",
    "plot_metrics(confusion_matrixes, indexes, indexes_result1, \"v\", \"Classifiers\", \"No. of samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion_matrixes = pd.DataFrame(confusion_matrixes, columns=indexes, index=[label for _, label in classifiers])\n",
    "df_confusion_matrixes.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_results = np.zeros((confusion_matrixes.shape[0], 10))\n",
    "for i in np.arange(confusion_matrixes.shape[0]):\n",
    "    perf_results[i,0:8] = perf_metrics(confusion_matrixes[i,:])\n",
    "\n",
    "# Calculate AUC and ROC curve and Mean Absolute Error (MEA)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "mae = dict()\n",
    "\n",
    "for index, classifier_info in enumerate(classifiers):\n",
    "    fpr[classifier_info[1]], tpr[classifier_info[1]], _ = roc_curve(y_test, classifier_info[0].predict(x_test))\n",
    "    roc_auc[classifier_info[1]] = auc(fpr[classifier_info[1]], tpr[classifier_info[1]])\n",
    "    mae[classifier_info[1]] = mean_absolute_error(y_test, classifier_info[0].predict(x_test))\n",
    "perf_results[:,8] = [roc_auc[i] for i in roc_auc]\n",
    "perf_results[:,9] = [mae[i] for i in mae]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_indexes = [\"CA\", \"Pre\", \"Spec\", \"Rec\", \"FPR\", \"NPV\", \"RMC\", \"F1\", \"AUC\", \"MAE\"] # that stands for Classification accuracy, Precision, Specificity, Recall/TP rate, \n",
    "# False positive rate, negative predictive value, misclassification rate and F1, respectively.\n",
    "indexes_result2 = [\"Pre\", \"Rec\", \"AUC\", \"MAE\", \"CA\"]\n",
    "\n",
    "plot_metrics(perf_results, metric_indexes, indexes_result2, \"h\", \"No. of samples\", \"Classifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_results = pd.DataFrame(perf_results, columns=metric_indexes, index=[label for _, label in classifiers])\n",
    "df_perf_results[indexes_result2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 4 equivalent\n",
    "result_labels = [\"TP\", \"FP\", \"Pre\", \"Rec\", \"AUC\", \"MAE\", \"CA\"]\n",
    "df_results_original = pd.concat([df_confusion_matrixes.T, df_perf_results.T]).T\n",
    "df_results_original[result_labels]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondaf49f642820f54471b5e35140d0937f58"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
